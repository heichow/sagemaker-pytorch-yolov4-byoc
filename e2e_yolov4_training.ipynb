{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end Pipeline for YoloV4 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will use a base implementation of the Yolov4 architecture which uses the PyTorch framework. We are using a forked version of this repo (https://github.com/Tianxiaomo/pytorch-YOLOv4) which has been modified for training with custom datasets. We have also made some minor adjustments to the forked repository to accomodate Amazon SageMaker Training.\n",
    "\n",
    "Before we train our model, we need to create our training container image and ensure our dataset is in the appropriate format for PyTorch Yolov4 models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Docker training image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps are best executed on your local machine or somewhere that has Docker installed.\n",
    "\n",
    "1. Navigate to this repository (https://github.com/kwwendt/sagemaker-yolov4-e2e-example) & follow the instructions to build, tag, and push the container to Amazon Elastic Container Registry.\n",
    "2. Once complete, return back to the notebook for the remaining steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload dataset to Amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this step, we will upload our dataset to Amazon S3 so we can easily load the data into our container during model training.\n",
    "\n",
    "In this demo, I am leveraging an open-source dataset provided by Roboflow: https://public.roboflow.com/object-detection/chess-full/24\n",
    "\n",
    "It is free to create an account and they have an easy export option for PyTorch Yolov4 compatible datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have your dataset, we can upload our data to Amazon S3. It is best to separate your training, validation, and testing data into 3 folders in S3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parameters & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install -q --upgrade sagemaker "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.session import Session\n",
    "\n",
    "sess = Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image URI for your docker training image\n",
    "docker_img_uri = \"<enter the output from the build_and_push_container.sh script>\"\n",
    "training_job_name = name_from_base('torch-yolov4-model')\n",
    "\n",
    "# Location where the trained model resides in S3\n",
    "model_path = f\"s3://{bucket}/{training_job_name}/output/model.tar.gz\"\n",
    "\n",
    "# Input shape and layer name\n",
    "input_shape = [1,3,608,608]\n",
    "input_layer_name = 'input0'\n",
    "data_shape = json.dumps({input_layer_name: input_shape})\n",
    "\n",
    "# Compiled model path for model compiled with Sagemaker Neo\n",
    "compiled_model_path = f\"s3://{bucket}/{training_job_name}/models/compiled\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create & train the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(\n",
    "    image_uri=docker_img_uri,\n",
    "    role=role,\n",
    "    instance_type=\"ml.g4dn.2xlarge\",\n",
    "    volume_size=50,\n",
    "    instance_count=1,\n",
    "    max_run = 6 * 60 *60,\n",
    "    hyperparameters={\n",
    "        \"pretrained\": \"yolov4.conv.137.pth\",\n",
    "        \"classes\": 13,\n",
    "        \"train_label\": \"_annotations.txt\", # If your annotations file is named differently, please note the correct name here\n",
    "        \"val_label\": \"_annotations.txt\", # If your annotations file is named differently, please note the correct name here\n",
    "        \"batch\": 2,\n",
    "        \"subdivisions\": 1,\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"gpu\": \"0\",\n",
    "        \"epochs\": 5\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(job_name=training_job_name, inputs={\n",
    "    \"train\": f\"s3://{bucket}/yolov4_training_data/trainv2/\", # The location in S3 where your training data and training annotations are stored\n",
    "    \"val\": f\"s3://{bucket}/yolov4_training_data/validv2/\" # The location in S3 where your validation data and validation annotations are stored\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Yolov4 repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to clone the Yolov4 repo we are using here so we can trace our trained model. Once you clone the repo, we need to move our notebook into the `pytorch-YOLOv4` directory so everything is on the same path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/roboflow-ai/pytorch-YOLOv4.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "\n",
    "with open('model.tar.gz', 'wb') as data:\n",
    "    s3_client.download_fileobj(Bucket=bucket, Key=f'{training_job_name}/output/model.tar.gz', Fileobj=data)\n",
    "weightfile = 'yolov4-trained-model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -zxvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import models\n",
    "\n",
    "model = models.Yolov4(n_classes=13)\n",
    "pretrained_dict = torch.load(weightfile, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(pretrained_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.zeros(input_shape).float()\n",
    "\n",
    "trace = torch.jit.trace(model.eval().float(), input1)\n",
    "trace.save('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czvf traced-yolov4-model.tar.gz model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model_path = sess.upload_data(path='traced-yolov4-model.tar.gz', key_prefix='models/traced')\n",
    "print(traced_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the compiled model with SageMaker Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Framework information\n",
    "framework = 'PYTORCH'\n",
    "framework_version = '1.7'\n",
    "compilation_job_name = f\"{training_job_name}-5\"\n",
    "\n",
    "sm_client = boto3.client('sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': traced_model_path,\n",
    "        'DataInputConfig': data_shape,\n",
    "        'Framework': framework,\n",
    "        'FrameworkVersion': framework_version\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': compiled_model_path,\n",
    "        'TargetDevice': 'ml_g4dn'\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 900 }    \n",
    ")\n",
    "\n",
    "import time\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to upload the `inference.py` entry point script so we can use it to create our model endpoint. Create a new folder called `code` and then upload the inference file into the new directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_vars = {\"COMPILEDMODEL\": 'True', 'MMS_MAX_RESPONSE_SIZE': '100000000', 'MMS_DEFAULT_RESPONSE_TIMEOUT': '120'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create SageMaker model and deploy an endpoint\n",
    "sm_pytorch_compiled_model = PyTorchModel(\n",
    "    model_data=f\"{compiled_model_path}/traced-yolov4-model-LINUX_X86_64.tar.gz\",\n",
    "    role=role,\n",
    "    entry_point='inference.py',\n",
    "    source_dir='code',\n",
    "    framework_version=framework_version,\n",
    "    py_version='py3',\n",
    "    env=env_vars\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the example instance_type below to your preferred instance_type\n",
    "predictor = sm_pytorch_compiled_model.deploy(initial_instance_count = 1, instance_type = 'ml.g4dn.xlarge')\n",
    "\n",
    "# Print the name of newly created endpoint\n",
    "print(predictor.endpoint_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our endpoint is deployed, you can test with a sample image from your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker-runtime', region_name=region)\n",
    "\n",
    "content_type = 'application/x-image'\n",
    "\n",
    "img_name = \"IMG_0293_JPG.rf.e208f5cdf5e993c552be7f96e86c4890.jpg\" # Add your image here\n",
    "\n",
    "with open(img_name, \"rb\") as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "\n",
    "response = client.invoke_endpoint(EndpointName=predictor.endpoint_name, Body=payload, ContentType=content_type)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 models.py 13 yolov4-trained-model.pth IMG_0293_JPG.rf.e208f5cdf5e993c552be7f96e86c4890.jpg dataset.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize inference\n",
    "from IPython.display import Image\n",
    "Image('predictions.jpg')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
